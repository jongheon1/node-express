{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jongheon1/node-express/blob/main/ML_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "602993e4-aeef-4d0f-8d9f-f5973c8e44e2",
      "metadata": {
        "id": "602993e4-aeef-4d0f-8d9f-f5973c8e44e2"
      },
      "source": [
        "cifar-10 데이터셋을 학습시켜 새와 비행기를 구분하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQEIk3Z0j7Qd",
        "outputId": "5fbfc52a-a044-49fb-f3da-bc4e557f3e2f"
      },
      "id": "zQEIk3Z0j7Qd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpu에서 돌아가도록 해 줍니다."
      ],
      "metadata": {
        "id": "5qgSn-qToyhY"
      },
      "id": "5qgSn-qToyhY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc61525-5c11-48e0-aeee-df1f461df3eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fc61525-5c11-48e0-aeee-df1f461df3eb",
        "outputId": "9055a0f5-e6a8-4117-c1d1-8393dc764183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch; torch.manual_seed(0)\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "data_path = '../data'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a37304-0c64-44bd-ab72-35852b3b249c",
      "metadata": {
        "id": "17a37304-0c64-44bd-ab72-35852b3b249c"
      },
      "source": [
        "cifar-10 데이터를 다운 받습니다. 훈련셋과 검증셋을 구분해서 다운받았습니다.\n",
        "\n",
        "\n",
        "cifar10은 자동으로 torch.utils.data.Dataset의 서브 클래스로 반환되기 때문에 따로 클래스를 만들어서 지정해 주지 않아도 됩니다. \n",
        "\n",
        "하지만 굳이 torch.utils.data.Dataset의 서브 클래스일 필요도 없습니다. 왜냐면 데이터셋은 작고, 인덱싱과 len만 있으면 되기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678010c6-86e6-4855-9862-9dcec5e9359d",
      "metadata": {
        "id": "678010c6-86e6-4855-9862-9dcec5e9359d"
      },
      "outputs": [],
      "source": [
        "label_map={0:0,2:1} #비행기는 cifar에서 0, 새는 cifar에서 2인데 이것을 각각 0 그리고 1로 바꾸어 줍니다.\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar = [(img, label_map[label]) for img, label in cifar10 if label in [0,2]]\n",
        "cifar_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0,2]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4168ac79-bef4-48ed-b73c-a1dad7ad5e85",
      "metadata": {
        "id": "4168ac79-bef4-48ed-b73c-a1dad7ad5e85"
      },
      "source": [
        "cifar10에 있는 데이터를 새와 비행기의 사진만 필터링하고 다시 매핑해서 새로운 데이터셋을 만들었습니다.\n",
        "\n",
        "이제 데이터를 넣을 모델이 필요합니다. 몇가지 모델을 이용해 학습시키고 성공률을 비교해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c572379-2a4d-4a3e-859d-0b7801de1bc1",
      "metadata": {
        "id": "1c572379-2a4d-4a3e-859d-0b7801de1bc1"
      },
      "outputs": [],
      "source": [
        "n_out = 2\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(\n",
        "        3072, #입력 피처, 이미지가 32*32*3인데 이를 1차원 벡터로 늘어뜨렸기 때문에 3072개의 입력 피처를 만들었습니다.\n",
        "        512, #임의로 512개의 은닉된 피처를 골랐습니다.\n",
        "    ),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(\n",
        "        512,\n",
        "        n_out,\n",
        "    ),\n",
        "    nn.Softmax(dim=1) #softmax = torch.exp(x)/torch.exp(x).sum()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa32a42d-4bad-49f3-a576-0a8d8893be71",
      "metadata": {
        "id": "aa32a42d-4bad-49f3-a576-0a8d8893be71"
      },
      "source": [
        "훈련 시키기 전 가장 기본적인 모델을 만들어보았습니다. softmax를 통해 수를 0과 1 사이로 바꾸어주었습니다.\n",
        "\n",
        "여기서 출력값은 카테고리입니다. 이상적인 경우 신경망은 비행기에 대해 torch.tensor([1.0,0.0])을 출력하고 새에 대해선 반대로 출력해야합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img,_ = cifar[0]\n",
        "img_batch = img.view(-1).unsqueeze(0)\n",
        "print(model(img_batch))\n",
        "plt.imshow(img.permute(1,2,0))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "atVwNnA6qbUI",
        "outputId": "7fa4e421-70dd-49fd-853e-0a286e6bf879"
      },
      "id": "atVwNnA6qbUI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4933, 0.5067]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 시키기 전 이미지입니다. \n",
        "\n",
        "출력이 확률의 형태로 나왔고 우연히 새를 의미하는 것이 나오긴 했지만 \n",
        "\n",
        "무작위로 초기화한 값이기 때문에 현재로선 아무런 의미가 없습니다."
      ],
      "metadata": {
        "id": "iZJu7pm8rkgP"
      },
      "id": "iZJu7pm8rkgP"
    },
    {
      "cell_type": "markdown",
      "id": "cd16fcff-38ce-42ea-ad05-f46bf316f49b",
      "metadata": {
        "id": "cd16fcff-38ce-42ea-ad05-f46bf316f49b"
      },
      "source": [
        "이제 모델에 이미지를 넣고 돌려서 훈련을 시킬 것입니다.\n",
        "\n",
        "먼저 NLL함수를 이용한 것입니다.\n",
        "\n",
        "learning rate는 1e-2이고\n",
        "\n",
        "optimizer는 SGD이고\n",
        "\n",
        "loss function은 NLLloss를 이용했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b34a630f-bdf3-41b8-9321-b0b98846b297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b34a630f-bdf3-41b8-9321-b0b98846b297",
        "outputId": "31df59ea-96d8-4d00-fc08-1c02a7c82eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.674485\n",
            "Epoch: 1, Loss: 0.617265\n",
            "Epoch: 2, Loss: 0.780723\n",
            "Epoch: 3, Loss: 0.559616\n",
            "Epoch: 4, Loss: 0.420487\n",
            "Epoch: 5, Loss: 0.587275\n",
            "Epoch: 6, Loss: 0.233775\n",
            "Epoch: 7, Loss: 0.375139\n",
            "Epoch: 8, Loss: 0.313992\n",
            "Epoch: 9, Loss: 0.592614\n",
            "Epoch: 10, Loss: 0.347440\n",
            "Epoch: 11, Loss: 0.418935\n",
            "Epoch: 12, Loss: 0.378459\n",
            "Epoch: 13, Loss: 0.474048\n",
            "Epoch: 14, Loss: 0.397035\n",
            "Epoch: 15, Loss: 0.293082\n",
            "Epoch: 16, Loss: 0.380939\n",
            "Epoch: 17, Loss: 0.409839\n",
            "Epoch: 18, Loss: 0.221208\n",
            "Epoch: 19, Loss: 0.836794\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss()\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213af4dc-6901-4a5b-93d2-2340840c8f7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "213af4dc-6901-4a5b-93d2-2340840c8f7f",
        "outputId": "ac44455d-e892-4c6c-ac13-daa031dcae29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.755100\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으론 다른건 위와 같이만 모델에 계층을 더 추가하였습니다"
      ],
      "metadata": {
        "id": "llL_JmwLshhR"
      },
      "id": "llL_JmwLshhR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3f5879-e4b1-446c-8956-ec689444fa78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d3f5879-e4b1-446c-8956-ec689444fa78",
        "outputId": "d927d7ef-7614-41cd-f0be-60218037427a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.596481\n",
            "Epoch: 1, Loss: 0.397408\n",
            "Epoch: 2, Loss: 0.374668\n",
            "Epoch: 3, Loss: 0.506387\n",
            "Epoch: 4, Loss: 0.339134\n",
            "Epoch: 5, Loss: 0.270393\n",
            "Epoch: 6, Loss: 0.468351\n",
            "Epoch: 7, Loss: 0.519288\n",
            "Epoch: 8, Loss: 0.486565\n",
            "Epoch: 9, Loss: 0.724310\n",
            "Epoch: 10, Loss: 0.463287\n",
            "Epoch: 11, Loss: 0.443597\n",
            "Epoch: 12, Loss: 0.685252\n",
            "Epoch: 13, Loss: 0.316082\n",
            "Epoch: 14, Loss: 0.483777\n",
            "Epoch: 15, Loss: 0.421172\n",
            "Epoch: 16, Loss: 0.540434\n",
            "Epoch: 17, Loss: 0.458017\n",
            "Epoch: 18, Loss: 0.497861\n",
            "Epoch: 19, Loss: 0.520904\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss()\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx6gD6mnnY7x",
        "outputId": "56660c03-8b33-4d49-dcbe-bc1985437b14"
      },
      "id": "Fx6gD6mnnY7x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.702900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 loss function 으로 cross entropy loss 를 사용한 것입니다."
      ],
      "metadata": {
        "id": "BgzgagSbsr0v"
      },
      "id": "BgzgagSbsr0v"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 2))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 20\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuhoTw8TnZJa",
        "outputId": "1a3f74c0-4473-4b6d-ed82-ce5aa4f7cc6b"
      },
      "id": "nuhoTw8TnZJa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.554711\n",
            "Epoch: 1, Loss: 0.530514\n",
            "Epoch: 2, Loss: 0.332666\n",
            "Epoch: 3, Loss: 0.442523\n",
            "Epoch: 4, Loss: 0.653080\n",
            "Epoch: 5, Loss: 0.332337\n",
            "Epoch: 6, Loss: 0.435411\n",
            "Epoch: 7, Loss: 0.496748\n",
            "Epoch: 8, Loss: 0.297147\n",
            "Epoch: 9, Loss: 0.427052\n",
            "Epoch: 10, Loss: 0.856349\n",
            "Epoch: 11, Loss: 0.430014\n",
            "Epoch: 12, Loss: 0.495227\n",
            "Epoch: 13, Loss: 0.672488\n",
            "Epoch: 14, Loss: 0.575489\n",
            "Epoch: 15, Loss: 0.432062\n",
            "Epoch: 16, Loss: 0.416063\n",
            "Epoch: 17, Loss: 0.406488\n",
            "Epoch: 18, Loss: 0.448870\n",
            "Epoch: 19, Loss: 0.530214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgi-QXwGnc9T",
        "outputId": "1b3cf276-98a7-4f29-8d98-2c1ab51879c9"
      },
      "id": "Dgi-QXwGnc9T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.680000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비교 결과 가장 처음 NLL을 이용한 것이 정확도가 가장 높게 나왔습니다."
      ],
      "metadata": {
        "id": "JRJcwVNktGq_"
      },
      "id": "JRJcwVNktGq_"
    },
    {
      "cell_type": "code",
      "source": [
        "sum([p.numel() for p in model.parameters()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMbVIlsxtMFQ",
        "outputId": "29cd2e39-b751-46a8-b28e-a985ca7d9522"
      },
      "id": "oMbVIlsxtMFQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3737474"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 파라미터 개수가 무려 370만개가 넘습니다.\n",
        "\n",
        " 이는 예측 가능한 것인데 먼저 x의 길이가 3072였고 1024개의 출력 피쳐를 만들었기 때문입니다.\n",
        "\n",
        "선형 계층이 y= weight*x+bias라면 3072*1024만 해도 300만이 넘습니다.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qTOuEYXetarQ"
      },
      "id": "qTOuEYXetarQ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VCYrsJzJuc04"
      },
      "id": "VCYrsJzJuc04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbq3WvSNuc5X"
      },
      "id": "nbq3WvSNuc5X",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}